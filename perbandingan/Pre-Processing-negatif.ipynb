{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7beb5877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total baris data setelah digabung: 50\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Definisikan semua nama file dalam sebuah list\n",
    "file_list = [\n",
    "    \"data/kotor/review_forrest_gump_B1.xlsx\",\n",
    "]\n",
    "\n",
    "# 2. Baca dan gabungkan file-file tersebut\n",
    "list_df = [pd.read_excel(file) for file in file_list]\n",
    "df = pd.concat(list_df, ignore_index=True)\n",
    "\n",
    "print(f\"Total baris data setelah digabung: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "804055ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Siapkan kolom kosong untuk hasil\n",
    "df['Komentar Bersih'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f09c0190",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\anlah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\anlah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\anlah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.data.path.append(r\"C:\\Users\\anlah\\AppData\\Roaming\\nltk_data\")\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "# 3. Siapkan alat NLP\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2770c964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Komentar  \\\n",
      "0  This movie suffers from a bad case of \"schizop...   \n",
      "1  Not being Tom Hanks' greatest fan, I avoided w...   \n",
      "2  This movie uses all the sappy, sentimental tri...   \n",
      "3  Perhaps one of the most overrated movies I hav...   \n",
      "4  This has to be one of the worst films I've eve...   \n",
      "\n",
      "                                     Komentar Bersih  \n",
      "0  movi suffer bad case schizophrenia movi start ...  \n",
      "1  tom hank greatest fan avoid watch film sever m...  \n",
      "2  movi use sappi sentiment trick book sucker aud...  \n",
      "3  perhap one overr movi ever seen fear societi a...  \n",
      "4  one worst film ive ever seen despit best effor...  \n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "df.drop(columns=['Tanggal', 'Judul'], inplace=True)\n",
    "\n",
    "# 4. Preprocessing satu per satu baris (tanpa fungsi)\n",
    "for i in range(len(df)):\n",
    "    #Ambil teks\n",
    "    text = str(df.loc[i, 'Komentar'])\n",
    "\n",
    "    #Lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    #Hapus tanda baca\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    #Tokenisasi\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    #Hapus stopword\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    #Stemming\n",
    "    tokens = [stemmer.stem(word) for word in tokens]\n",
    "\n",
    "    #Gabungkan kembali\n",
    "    clean_text = ' '.join(tokens)\n",
    "\n",
    "    #Simpan ke kolom baru\n",
    "    df.loc[i, 'Komentar Bersih'] = clean_text\n",
    "\n",
    "#tampilkan 5 data teratas\n",
    "print(df[['Komentar', 'Komentar Bersih']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127f5ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Pre-processing selesai, hasil disimpan ke dataset\n"
     ]
    }
   ],
   "source": [
    "# 5. Simpan hasil\n",
    "df.drop(columns=['Komentar'], inplace=True)\n",
    "df.to_excel(\"data/bersih/data_clean_forrest_gump_negatif.xlsx\", index=False)\n",
    "print(\" Pre-processing selesai, hasil disimpan ke dataset\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
