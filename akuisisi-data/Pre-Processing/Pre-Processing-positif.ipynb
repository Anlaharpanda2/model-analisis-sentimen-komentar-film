{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7beb5877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total baris data setelah digabung: 1000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Definisikan semua nama file dalam sebuah list\n",
    "file_list = [\n",
    "    \"../positif/review_300_B10.xlsx\",\n",
    "    \"../positif/review_300_B9.xlsx\",\n",
    "    \"../positif/review_300_B8.xlsx\"\n",
    "]\n",
    "\n",
    "# 2. Baca dan gabungkan file-file tersebut\n",
    "list_df = [pd.read_excel(file) for file in file_list]\n",
    "df = pd.concat(list_df, ignore_index=True)\n",
    "\n",
    "print(f\"Total baris data setelah digabung: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "804055ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Siapkan kolom kosong untuk hasil\n",
    "df['Komentar Bersih'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f09c0190",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\anlah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\anlah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\anlah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.data.path.append(r\"C:\\Users\\anlah\\AppData\\Roaming\\nltk_data\")\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "# 3. Siapkan alat NLP\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2770c964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Komentar  \\\n",
      "0  After I saw the teaser for 300 I knew I HAD to...   \n",
      "1  I have been at the World Premiere of 300 in Be...   \n",
      "2  After seeing a 99% complete 300 at a 24 hour f...   \n",
      "3  '300' is a totally riveting masterpiece of fil...   \n",
      "4  I was one of the 1700 lucky viewers to get a t...   \n",
      "\n",
      "                                     Komentar Bersih  \n",
      "0  saw teaser 300 knew see movi avoid preview rev...  \n",
      "1  world premier 300 berlin watch fantast movi Â– ...  \n",
      "2  see 99 complet 300 24 hour film festiv amaz ac...  \n",
      "3  300 total rivet masterpiec film make zack snyd...  \n",
      "4  one 1700 lucki viewer get ticket world premier...  \n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "df.drop(columns=['Tanggal', 'Judul'], inplace=True)\n",
    "\n",
    "# 4. Preprocessing satu per satu baris (tanpa fungsi)\n",
    "for i in range(len(df)):\n",
    "    #Ambil teks\n",
    "    text = str(df.loc[i, 'Komentar'])\n",
    "\n",
    "    #Lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    #Hapus tanda baca\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    #Tokenisasi\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    #Hapus stopword\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    #Stemming\n",
    "    tokens = [stemmer.stem(word) for word in tokens]\n",
    "\n",
    "    #Gabungkan kembali\n",
    "    clean_text = ' '.join(tokens)\n",
    "\n",
    "    #Simpan ke kolom baru\n",
    "    df.loc[i, 'Komentar Bersih'] = clean_text\n",
    "\n",
    "#tampilkan 5 data teratas\n",
    "print(df[['Komentar', 'Komentar Bersih']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127f5ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Pre-processing selesai, hasil disimpan ke dataset\n"
     ]
    }
   ],
   "source": [
    "# 5. Simpan hasil\n",
    "df.drop(columns=['Komentar'], inplace=True)\n",
    "df.to_excel(\"../../dataset/data_clean_300_positif.xlsx\", index=False)\n",
    "print(\" Pre-processing selesai, hasil disimpan ke dataset\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
